# FindableX Production Docker Compose
# Optimized for Aliyun ECS Ubuntu 24.04 LTS
# Usage: docker compose -f deploy/docker-compose.yml up -d
# 
# 注意: 基础镜像使用阿里云镜像加速，需要在服务器上配置 Docker daemon:
# /etc/docker/daemon.json 中添加 registry-mirrors

services:
  # ===========================================
  # PostgreSQL Database
  # ===========================================
  postgres:
    image: postgres:16-alpine
    container_name: findablex-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${DB_USER:-findablex}
      POSTGRES_PASSWORD: ${DB_PASSWORD:?DB_PASSWORD is required}
      POSTGRES_DB: ${DB_NAME:-findablex}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-findablex} -d ${DB_NAME:-findablex}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - findablex-network
    deploy:
      resources:
        limits:
          memory: 1G

  # ===========================================
  # Redis Cache & Message Queue
  # ===========================================
  redis:
    image: redis:7-alpine
    container_name: findablex-redis
    restart: unless-stopped
    command: >
      redis-server 
      --appendonly yes 
      --maxmemory 256mb 
      --maxmemory-policy allkeys-lru
      --save 60 1
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - findablex-network
    deploy:
      resources:
        limits:
          memory: 512M

  # ===========================================
  # Backend API (with integrated crawler)
  # ===========================================
  api:
    build:
      context: ./packages/api
      dockerfile: ../../Dockerfile.api
    image: findablex/api:${VERSION:-latest}
    container_name: findablex-api
    restart: unless-stopped
    environment:
      # Database
      DATABASE_URL: postgresql+asyncpg://${DB_USER:-findablex}:${DB_PASSWORD}@postgres:5432/${DB_NAME:-findablex}
      
      # Redis
      REDIS_URL: redis://redis:6379/0
      
      # Security
      JWT_SECRET: ${JWT_SECRET:?JWT_SECRET is required}
      
      # App Config
      ENV: production
      DEBUG: "false"
      LITE_MODE: "true"
      
      # CORS
      ALLOWED_ORIGINS: ${ALLOWED_ORIGINS:-https://findablex.com}
      
      # Crawler Config
      CRAWLER_HEADLESS: "true"
      CRAWLER_DATA_DIR: /app/data
      
      # Optional: AI API Keys (if using API mode instead of browser)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      QWEN_API_KEY: ${QWEN_API_KEY:-}
      
    volumes:
      - api_data:/app/data
      - api_uploads:/app/uploads
    ports:
      - "127.0.0.1:8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - findablex-network
    # Required for Playwright
    security_opt:
      - seccomp=unconfined
    deploy:
      resources:
        limits:
          memory: 2G

  # ===========================================
  # Frontend Web (Next.js)
  # ===========================================
  web:
    build:
      context: ./packages/web
      dockerfile: ../../Dockerfile.web
      args:
        NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-/api}
    image: findablex/web:${VERSION:-latest}
    container_name: findablex-web
    restart: unless-stopped
    environment:
      NODE_ENV: production
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-/api}
    ports:
      - "127.0.0.1:3000:3000"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - findablex-network
    deploy:
      resources:
        limits:
          memory: 512M

  # ===========================================
  # Nginx Reverse Proxy (with SSL)
  # findablex.com - 47.121.136.144
  # ===========================================
  nginx:
    image: nginx:alpine
    container_name: findablex-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - nginx_cache:/var/cache/nginx
      - nginx_logs:/var/log/nginx
    depends_on:
      - api
      - web
    networks:
      - findablex-network
    deploy:
      resources:
        limits:
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================
  # Crawler Agent (Optional - for remote browser)
  # Run this on a machine with browser access
  # ===========================================
  # crawler-agent:
  #   build:
  #     context: ../packages/crawler-agent
  #     dockerfile: Dockerfile
  #   image: findablex/crawler-agent:${VERSION:-latest}
  #   container_name: findablex-crawler-agent
  #   restart: unless-stopped
  #   environment:
  #     API_URL: http://api:8000
  #     AGENT_TOKEN: ${CRAWLER_AGENT_TOKEN}
  #   depends_on:
  #     - api
  #   networks:
  #     - findablex-network

networks:
  findablex-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  api_data:
  api_uploads:
  nginx_cache:
  nginx_logs:
